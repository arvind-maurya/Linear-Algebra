{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIML-CEP-LA.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arvind-maurya/Linear-Algebra/blob/main/AIML_CEP_LA_IRIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MXB7T3QmIYT"
      },
      "source": [
        "#Linear Algebra - Motivation by an application#\n",
        "\n",
        "Let us consider the $\\textit{wine}$ data set from scikit-learn package. Let us load the data set and analyze its structure. \n",
        "\n",
        "We shall check the following:\n",
        "\n",
        "\n",
        "\n",
        "1.   Number of instances (or samples)\n",
        "2.   Number of attributes (or features)\n",
        "3.   Description of attributes \n",
        "4.   Type of class labels (which might not be necessary for today's discussion)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A15Vcn5_mycH"
      },
      "source": [
        "import numpy as np #numpy package will be useful for most of the array operations in the code \n",
        "from sklearn.datasets import load_wine"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgOvl25BnWyq"
      },
      "source": [
        "#Let us load the wine data and store the result in X_y variable. The idea behind naming of the variable will be illustrated in the next few tabs.\n",
        "X_y = load_wine()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CcM8qwnndnJ",
        "outputId": "1577f9d9-a583-40a8-f091-b5a6439143d5"
      },
      "source": [
        "#Let us print the contents of the X_y variable \n",
        "\n",
        "print(type(X_y))\n",
        "print(X_y)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n",
            "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
            "        1.065e+03],\n",
            "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
            "        1.050e+03],\n",
            "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
            "        1.185e+03],\n",
            "       ...,\n",
            "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
            "        8.350e+02],\n",
            "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
            "        8.400e+02],\n",
            "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
            "        5.600e+02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2]), 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'), 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n', 'feature_names': ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DrlYUrWnxrd",
        "outputId": "01cd2fda-7836-418e-b0da-1d8abe9ff72f"
      },
      "source": [
        "#So we found that the X_y variable is of type sklearn.utils.bunch\n",
        "#further, we see that the X_y variable consists of dictionary-type structures named \"data\",  \"target\" and \"target_names\"\n",
        "\n",
        "# Let us now segregate the data attributes and class labels into separate variables \n",
        "\n",
        "X = X_y.data\n",
        "y = X_y.target\n",
        "\n",
        "print('X shape:', X.shape, 'type(X):', type(X) )\n",
        "print(' y shape:', y.shape, ' type(y):', type(y))\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (178, 13) type(X): <class 'numpy.ndarray'>\n",
            " y shape: (178,)  type(y): <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHQorN2tp-D1",
        "outputId": "7ecda1dc-0640-4e70-f9e2-5a8d6050a21b"
      },
      "source": [
        "#Thus we see that X and y are numpy ndarrays. \n",
        "#We also see that there are 178 samples (or instances) in the data set and each sample has 13 attributes. \n",
        "#The shape of target variable y indicates that y contains the labels for these 178 samples\n",
        "\n",
        "#We can print the unique labels available in y \n",
        "print(np.unique(y))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyANKhhDpxgb",
        "outputId": "d5a77b04-673c-499e-b305-5e5f4cca44ec"
      },
      "source": [
        "# Let us also segregate the data set description into a different variable and check the contents\n",
        "X_y_description = X_y.DESCR\n",
        "print('type(X_y_description):', type(X_y_description))\n",
        "print(X_y_description)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(X_y_description): <class 'str'>\n",
            ".. _wine_dataset:\n",
            "\n",
            "Wine recognition dataset\n",
            "------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 178 (50 in each of three classes)\n",
            "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            " \t\t- Alcohol\n",
            " \t\t- Malic acid\n",
            " \t\t- Ash\n",
            "\t\t- Alcalinity of ash  \n",
            " \t\t- Magnesium\n",
            "\t\t- Total phenols\n",
            " \t\t- Flavanoids\n",
            " \t\t- Nonflavanoid phenols\n",
            " \t\t- Proanthocyanins\n",
            "\t\t- Color intensity\n",
            " \t\t- Hue\n",
            " \t\t- OD280/OD315 of diluted wines\n",
            " \t\t- Proline\n",
            "\n",
            "    - class:\n",
            "            - class_0\n",
            "            - class_1\n",
            "            - class_2\n",
            "\t\t\n",
            "    :Summary Statistics:\n",
            "    \n",
            "    ============================= ==== ===== ======= =====\n",
            "                                   Min   Max   Mean     SD\n",
            "    ============================= ==== ===== ======= =====\n",
            "    Alcohol:                      11.0  14.8    13.0   0.8\n",
            "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
            "    Ash:                          1.36  3.23    2.36  0.27\n",
            "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
            "    Magnesium:                    70.0 162.0    99.7  14.3\n",
            "    Total Phenols:                0.98  3.88    2.29  0.63\n",
            "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
            "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
            "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
            "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
            "    Hue:                          0.48  1.71    0.96  0.23\n",
            "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
            "    Proline:                       278  1680     746   315\n",
            "    ============================= ==== ===== ======= =====\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "This is a copy of UCI ML Wine recognition datasets.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
            "\n",
            "The data is the results of a chemical analysis of wines grown in the same\n",
            "region in Italy by three different cultivators. There are thirteen different\n",
            "measurements taken for different constituents found in the three types of\n",
            "wine.\n",
            "\n",
            "Original Owners: \n",
            "\n",
            "Forina, M. et al, PARVUS - \n",
            "An Extendible Package for Data Exploration, Classification and Correlation. \n",
            "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
            "Via Brigata Salerno, 16147 Genoa, Italy.\n",
            "\n",
            "Citation:\n",
            "\n",
            "Lichman, M. (2013). UCI Machine Learning Repository\n",
            "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
            "School of Information and Computer Science. \n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  Comparison of Classifiers in High Dimensional Settings, \n",
            "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Technometrics). \n",
            "\n",
            "  The data was used with many others for comparing various \n",
            "  classifiers. The classes are separable, though only RDA \n",
            "  has achieved 100% correct classification. \n",
            "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
            "  (All results using the leave-one-out technique) \n",
            "\n",
            "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
            "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Journal of Chemometrics).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq3Nns2rrTsd",
        "outputId": "4ab240ea-b2a5-4b01-bb9f-17cdd5bb2611"
      },
      "source": [
        "#Let us focus our discussion on the feature matrix X and keep aside the label matrix y for the time being.\n",
        "\n",
        "#Let us compute two new matrices from X. \n",
        "\n",
        "XXT = np.matmul(X,np.transpose(X)) #X X^T matrix \n",
        "XTX = np.matmul(X.T,X) #X^T X matrix \n",
        "\n",
        "print('XXT shape:', XXT.shape, 'XTX shape:', XTX.shape)\n",
        "\n",
        "print(X)\n",
        "\n",
        "print(np.transpose(X))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XXT shape: (178, 178) XTX shape: (13, 13)\n",
            "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
            " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
            " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
            " ...\n",
            " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
            " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
            " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
            "[[1.423e+01 1.320e+01 1.316e+01 ... 1.327e+01 1.317e+01 1.413e+01]\n",
            " [1.710e+00 1.780e+00 2.360e+00 ... 4.280e+00 2.590e+00 4.100e+00]\n",
            " [2.430e+00 2.140e+00 2.670e+00 ... 2.260e+00 2.370e+00 2.740e+00]\n",
            " ...\n",
            " [1.040e+00 1.050e+00 1.030e+00 ... 5.900e-01 6.000e-01 6.100e-01]\n",
            " [3.920e+00 3.400e+00 3.170e+00 ... 1.560e+00 1.620e+00 1.600e+00]\n",
            " [1.065e+03 1.050e+03 1.185e+03 ... 8.350e+02 8.400e+02 5.600e+02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J8ka1lTu58y"
      },
      "source": [
        "$XX^\\top$ and $X^\\top X$ are called covariance matrices. \n",
        "\n",
        "In particular, $XX^\\top$ is of shape $\\textit{num samples} \\times \\textit{num samples}$ and captures the correlation (upto scaling) between distinct samples in the data set. Hence we call $XX^\\top$ to be sample covariance matrix. \n",
        "\n",
        "Similarly, $X^\\top X$ is of shape $\\textit{num features} \\times \\textit{num features}$ and captures the correlation (upto scaling) between different attributes in the data set.  Hence we call $X^\\top X$ to be feature covariance matrix. \n",
        "\n",
        "In fact, these covariance matrices satisfy several important properties: \n",
        "\n",
        "\n",
        "\n",
        "1.   $XX^\\top$ and $X^\\top X$ are square and symmetric  \n",
        "2.   $XX^\\top$ and $X^\\top X$ are positive semi-definite (that is, their eigen values are non-negative)\n",
        "3.   $XX^\\top$ and $X^\\top X$ have same positive eigen values.  \n",
        "4.   $XX^\\top$ and $X^\\top X$ have the same rank as $X$ \n",
        "\n",
        "Let us quickly check each of these facts. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5-_UHmht5bd",
        "outputId": "47b9b7ee-c981-4285-a4ed-f02926ec1b73"
      },
      "source": [
        "#checking if XXT and XTX are square and symmetric\n",
        "\n",
        "\n",
        "print('XXT matrix:')\n",
        "if XXT.shape[0] == XXT.shape[1]:\n",
        "  print('XXT is square')\n",
        "else:\n",
        "  print('XXT is not square')\n",
        "\n",
        "if np.all(XXT == XXT.T):\n",
        "  print('XXT is symmetric')\n",
        "else:\n",
        "  print('XXT is not symmetric')\n",
        "\n",
        "\n",
        "print('XTX matrix:')\n",
        "if XTX.shape[0] == XTX.shape[1]:\n",
        "  print('XTX is square')\n",
        "else:\n",
        "  print('XTX is not square')\n",
        "\n",
        "if np.all(XTX == XTX.T):\n",
        "  print('XTX is symmetric')\n",
        "else:\n",
        "  print('XTX is not symmetric')\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XXT matrix:\n",
            "XXT is square\n",
            "XXT is symmetric\n",
            "XTX matrix:\n",
            "XTX is square\n",
            "XTX is symmetric\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNLG-KE771-V",
        "outputId": "5857f9e2-bb76-41d1-d997-2023dfed5b5b"
      },
      "source": [
        "#checking if XXT and XTX are positive semi-definite\n",
        "#First we will use linalg.eig in numpy, which can be used to find eigen values and eigen vectors for any square matrix\n",
        "\n",
        "print('eigen values of XXT:')\n",
        "eig_val_XXT, eig_vec_XXT = np.linalg.eig(XXT)\n",
        "print(eig_val_XXT)\n",
        "\n",
        "print('eigen values of XTX:')\n",
        "eig_val_XTX, eig_vec_XTX = np.linalg.eig(XTX)\n",
        "print(eig_val_XTX)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eigen values of XXT:\n",
            "[ 1.18519582e+08+0.00000000e+00j  2.43603495e+05+0.00000000e+00j\n",
            "  3.26599028e+03+0.00000000e+00j  9.06017549e+02+0.00000000e+00j\n",
            "  3.43836011e+02+0.00000000e+00j  2.09178961e+02+0.00000000e+00j\n",
            "  1.21794126e+02+0.00000000e+00j  2.79829387e+01+0.00000000e+00j\n",
            "  1.98611790e+01+0.00000000e+00j  1.27825659e+01+0.00000000e+00j\n",
            "  6.76635454e+00+0.00000000e+00j  3.94740676e+00+0.00000000e+00j\n",
            "  1.47358714e+00+0.00000000e+00j -1.21485711e-08+0.00000000e+00j\n",
            "  6.07006165e-09+7.48821506e-09j  6.07006165e-09-7.48821506e-09j\n",
            " -2.44843502e-09+8.44958710e-09j -2.44843502e-09-8.44958710e-09j\n",
            "  6.05133352e-09+0.00000000e+00j -5.84159307e-09+0.00000000e+00j\n",
            "  1.83352726e-09+5.12116458e-09j  1.83352726e-09-5.12116458e-09j\n",
            " -5.14421605e-09+0.00000000e+00j -6.20504969e-10+5.17089683e-09j\n",
            " -6.20504969e-10-5.17089683e-09j  4.83675532e-09+0.00000000e+00j\n",
            "  2.82559893e-09+3.56667005e-09j  2.82559893e-09-3.56667005e-09j\n",
            " -2.21991728e-09+3.66158223e-09j -2.21991728e-09-3.66158223e-09j\n",
            "  3.87490489e-09+0.00000000e+00j -2.54855380e-09+2.01298256e-09j\n",
            " -2.54855380e-09-2.01298256e-09j -2.46832463e-09+7.71976609e-10j\n",
            " -2.46832463e-09-7.71976609e-10j -2.54509268e-09+0.00000000e+00j\n",
            "  3.67012803e-10+2.33313951e-09j  3.67012803e-10-2.33313951e-09j\n",
            " -3.44491347e-10+2.29115061e-09j -3.44491347e-10-2.29115061e-09j\n",
            " -8.90174051e-10+2.08319864e-09j -8.90174051e-10-2.08319864e-09j\n",
            "  2.25710987e-09+0.00000000e+00j  1.78535786e-09+1.33844225e-09j\n",
            "  1.78535786e-09-1.33844225e-09j  1.15624814e-09+1.83717536e-09j\n",
            "  1.15624814e-09-1.83717536e-09j -2.19415936e-09+0.00000000e+00j\n",
            " -1.75653511e-09+9.82048254e-10j -1.75653511e-09-9.82048254e-10j\n",
            " -1.96632538e-09+2.59050426e-10j -1.96632538e-09-2.59050426e-10j\n",
            " -1.15060221e-09+1.47321700e-09j -1.15060221e-09-1.47321700e-09j\n",
            "  1.78733617e-09+4.92358765e-10j  1.78733617e-09-4.92358765e-10j\n",
            "  9.50698976e-10+1.59320931e-09j  9.50698976e-10-1.59320931e-09j\n",
            " -3.40355706e-12+1.74850409e-09j -3.40355706e-12-1.74850409e-09j\n",
            "  1.75795090e-09+0.00000000e+00j  1.45572969e-09+9.58117645e-10j\n",
            "  1.45572969e-09-9.58117645e-10j  1.20769413e-09+1.03978092e-09j\n",
            "  1.20769413e-09-1.03978092e-09j -8.22141104e-10+1.39946284e-09j\n",
            " -8.22141104e-10-1.39946284e-09j -5.95643146e-10+1.43980400e-09j\n",
            " -5.95643146e-10-1.43980400e-09j -1.10245443e-09+1.05067976e-09j\n",
            " -1.10245443e-09-1.05067976e-09j  7.09243441e-10+1.28920986e-09j\n",
            "  7.09243441e-10-1.28920986e-09j -4.53993490e-10+1.38617917e-09j\n",
            " -4.53993490e-10-1.38617917e-09j -1.34511158e-09+3.07808063e-10j\n",
            " -1.34511158e-09-3.07808063e-10j -1.24072454e-09+4.92068304e-10j\n",
            " -1.24072454e-09-4.92068304e-10j  1.32185799e-09+1.05843677e-10j\n",
            "  1.32185799e-09-1.05843677e-10j  1.18343137e-09+5.08108083e-10j\n",
            "  1.18343137e-09-5.08108083e-10j -1.89694044e-10+1.27177626e-09j\n",
            " -1.89694044e-10-1.27177626e-09j -1.25097031e-09+1.24551976e-10j\n",
            " -1.25097031e-09-1.24551976e-10j  5.12778375e-10+1.08131018e-09j\n",
            "  5.12778375e-10-1.08131018e-09j  7.31048050e-10+9.22972754e-10j\n",
            "  7.31048050e-10-9.22972754e-10j -3.95802824e-10+1.11596207e-09j\n",
            " -3.95802824e-10-1.11596207e-09j  2.64254355e-10+1.13202730e-09j\n",
            "  2.64254355e-10-1.13202730e-09j  1.03773846e-09+3.20179152e-10j\n",
            "  1.03773846e-09-3.20179152e-10j -1.02269231e-09+0.00000000e+00j\n",
            "  5.03997913e-11+1.01787450e-09j  5.03997913e-11-1.01787450e-09j\n",
            "  6.87724471e-10+6.90762413e-10j  6.87724471e-10-6.90762413e-10j\n",
            " -7.42126624e-10+5.32798288e-10j -7.42126624e-10-5.32798288e-10j\n",
            " -3.21960637e-10+8.33774347e-10j -3.21960637e-10-8.33774347e-10j\n",
            " -5.17259231e-10+6.64357660e-10j -5.17259231e-10-6.64357660e-10j\n",
            "  5.40147951e-10+5.87597022e-10j  5.40147951e-10-5.87597022e-10j\n",
            "  8.05685077e-10+0.00000000e+00j  7.75766009e-10+2.06018534e-10j\n",
            "  7.75766009e-10-2.06018534e-10j -7.92874601e-10+1.17033222e-10j\n",
            " -7.92874601e-10-1.17033222e-10j -6.88856415e-10+3.16675197e-10j\n",
            " -6.88856415e-10-3.16675197e-10j  1.19095631e-11+7.56193592e-10j\n",
            "  1.19095631e-11-7.56193592e-10j  6.97409221e-10+2.23290480e-10j\n",
            "  6.97409221e-10-2.23290480e-10j  4.44667280e-10+5.68900202e-10j\n",
            "  4.44667280e-10-5.68900202e-10j  5.48819881e-10+4.39902757e-10j\n",
            "  5.48819881e-10-4.39902757e-10j -5.75919253e-11+7.20126295e-10j\n",
            " -5.75919253e-11-7.20126295e-10j -7.20665691e-10+0.00000000e+00j\n",
            " -4.08695412e-10+5.19161748e-10j -4.08695412e-10-5.19161748e-10j\n",
            "  5.76677313e-10+2.57181405e-10j  5.76677313e-10-2.57181405e-10j\n",
            "  5.19027318e-10+2.13178522e-10j  5.19027318e-10-2.13178522e-10j\n",
            " -1.24395547e-10+5.69172687e-10j -1.24395547e-10-5.69172687e-10j\n",
            " -4.87039049e-10+3.35136128e-10j -4.87039049e-10-3.35136128e-10j\n",
            " -5.56649700e-10+2.01939753e-10j -5.56649700e-10-2.01939753e-10j\n",
            "  7.24141662e-11+5.54577154e-10j  7.24141662e-11-5.54577154e-10j\n",
            "  2.47777690e-10+4.56862455e-10j  2.47777690e-10-4.56862455e-10j\n",
            " -5.49082441e-10+0.00000000e+00j -1.72893553e-10+4.41960446e-10j\n",
            " -1.72893553e-10-4.41960446e-10j  4.86580095e-10+1.66181764e-11j\n",
            "  4.86580095e-10-1.66181764e-11j  3.25749954e-10+3.00007803e-10j\n",
            "  3.25749954e-10-3.00007803e-10j -3.54667939e-10+2.15952978e-10j\n",
            " -3.54667939e-10-2.15952978e-10j  2.15628255e-10+3.04269587e-10j\n",
            "  2.15628255e-10-3.04269587e-10j -1.26595539e-10+3.52331392e-10j\n",
            " -1.26595539e-10-3.52331392e-10j -2.10033572e-10+2.78559796e-10j\n",
            " -2.10033572e-10-2.78559796e-10j -3.75076748e-10+0.00000000e+00j\n",
            "  2.55042374e-10+0.00000000e+00j  1.14829282e-10+1.99403410e-10j\n",
            "  1.14829282e-10-1.99403410e-10j  6.58176235e-11+3.06813869e-10j\n",
            "  6.58176235e-11-3.06813869e-10j -2.97023742e-10+7.60345187e-11j\n",
            " -2.97023742e-10-7.60345187e-11j  3.23818123e-10+0.00000000e+00j\n",
            "  1.69231152e-10+0.00000000e+00j  7.15551370e-12+1.21291027e-10j\n",
            "  7.15551370e-12-1.21291027e-10j  7.66740411e-11+0.00000000e+00j\n",
            " -1.74552248e-10+8.82817163e-11j -1.74552248e-10-8.82817163e-11j\n",
            " -1.84893646e-10+0.00000000e+00j -5.75126464e-11+6.59740977e-11j\n",
            " -5.75126464e-11-6.59740977e-11j -4.88326465e-11+0.00000000e+00j]\n",
            "eigen values of XTX:\n",
            "[1.18519582e+08 2.43603495e+05 3.26599028e+03 9.06017549e+02\n",
            " 3.43836011e+02 2.09178961e+02 1.21794126e+02 2.79829387e+01\n",
            " 1.98611790e+01 1.27825659e+01 6.76635454e+00 3.94740676e+00\n",
            " 1.47358714e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC5cQ2qS7spe"
      },
      "source": [
        "## Important note about the results obtained from $\\texttt{np.linalg.eig}$## \n",
        "\n",
        "Note that the results from $\\texttt{np.linalg.eig}$ show complex eigen values for $XX^\\top$ matrix. \n",
        "\n",
        "However from theory if $A$ is a real symmetric matrix, then the eigen values need to be real. We present a proof of the result below. \n",
        "\n",
        "So, the results from $\\texttt{np.linalg.eig}$ are due to numerical errors due to floating point approximations and truncations involved in the algorithms used to compute the eigen values and eigen vectors. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0pN9buqQRZw"
      },
      "source": [
        "$\\textbf{Result:}$ If $A$ is a real symmetric matrix, then the eigen values are real. \n",
        "\n",
        "A simple proof is as below: \n",
        "\n",
        "Let $\\lambda$ be a complex number of the form $a+bi$ which is an eigen value for a real symmetric matrix $A$ corresponding to the eigen vector $x\\neq \\mathbf{0}$. Recall that the complex conjugate $\\bar{\\lambda}$ of $\\lambda$ is given by $a-bi$. \n",
        "\n",
        "Then we have:\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "Ax &= \\lambda x \\nonumber \\\\\n",
        "\\text{Taking complex conjugates } & \\text { on both sides, we have} \\nonumber \\\\\n",
        "\\overline{Ax} &= \\overline{\\lambda x} \\nonumber \\\\\n",
        "\\bar{A} \\bar{x} &= \\bar{\\lambda} \\bar{x} \\nonumber \\\\\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "However $\\bar{A} = A$ since $A$ is real. Thus we have $A\\bar{x} = \\bar{\\lambda} \\bar{x}$. Hence $\\bar{x} \\neq \\mathbf{0}$ is an eigen vector of $A$ with a corresponding eigen value $\\bar{\\lambda}$.   \n",
        "\n",
        "Now consider $A \\bar{x} = \\lambda \\bar{x}$. Pre-multiplying by $x^\\top$ we have:\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "x^\\top A \\bar{x} &= \\lambda x^\\top \\bar{x} \\nonumber \\\\\n",
        "(Ax)^\\top \\bar{x} &= \\lambda x^\\top \\bar{x} \\nonumber \\\\\n",
        "\\implies (\\lambda x)^\\top \\bar{x} &= \\lambda x^\\top \\bar{x} \\nonumber \\\\\n",
        "\\lambda x^\\top \\bar{x} &= \\lambda x^\\top \\bar{x} \\nonumber \\\\\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "Since $r=x^\\top \\bar{x} \\neq 0$ is a real quantity $\\textbf{(check this!)}$ we have:   $\\lambda r=\\bar{\\lambda} r \\implies \\lambda =\\bar{\\lambda}$. \n",
        "\n",
        "Now $\\lambda = \\bar{\\lambda} \\implies a+bi = a-bi$ is possible if and only if $b=0$ or $\\lambda$ is a real number. Hence the proof follows. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0zo0Z23ybGu",
        "outputId": "0da90721-9074-4f1e-8ac6-688355a11f57"
      },
      "source": [
        "#checking if XXT and XTX are positive semi-definite\n",
        "#we will use linalg.eigh in numpy, which can be useful for symmetric matrices \n",
        "\n",
        "print('eigen values of XXT:')\n",
        "eig_val_XXT, eig_vec_XXT = np.linalg.eigh(XXT)\n",
        "print(eig_val_XXT)\n",
        "\n",
        "print('eigen values of XTX:')\n",
        "eig_val_XTX, eig_vec_XTX = np.linalg.eigh(XTX)\n",
        "print(eig_val_XTX)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eigen values of XXT:\n",
            "[-3.36866745e-08 -1.50220377e-08 -1.48359545e-08 -1.27703210e-08\n",
            " -1.12251019e-08 -8.61716632e-09 -7.68185582e-09 -6.08380757e-09\n",
            " -5.20923555e-09 -4.79181820e-09 -4.64584954e-09 -4.45823382e-09\n",
            " -4.06583460e-09 -3.76302785e-09 -3.52082671e-09 -3.48366439e-09\n",
            " -3.19645170e-09 -3.10620238e-09 -2.93389846e-09 -2.77958523e-09\n",
            " -2.56766319e-09 -2.50504266e-09 -2.30319114e-09 -2.20061929e-09\n",
            " -2.14217319e-09 -2.08954272e-09 -1.96743185e-09 -1.84108486e-09\n",
            " -1.80269071e-09 -1.71241283e-09 -1.51163812e-09 -1.48936809e-09\n",
            " -1.48435290e-09 -1.35417436e-09 -1.24807262e-09 -1.22321156e-09\n",
            " -1.20566808e-09 -1.13322046e-09 -1.11424634e-09 -1.09010928e-09\n",
            " -1.08372074e-09 -1.06103073e-09 -1.03223767e-09 -9.47104518e-10\n",
            " -9.09229967e-10 -8.51452866e-10 -8.02550788e-10 -7.64072662e-10\n",
            " -7.60879699e-10 -7.10046986e-10 -7.09985259e-10 -6.32793396e-10\n",
            " -6.23683235e-10 -6.11804021e-10 -5.96182200e-10 -5.64414286e-10\n",
            " -5.50822138e-10 -5.22651034e-10 -5.18204553e-10 -4.73363967e-10\n",
            " -4.69052307e-10 -4.18885367e-10 -3.94884877e-10 -3.87769120e-10\n",
            " -3.76018153e-10 -3.65119848e-10 -3.20706412e-10 -3.01678535e-10\n",
            " -2.99146215e-10 -2.72855423e-10 -2.54613653e-10 -2.53768335e-10\n",
            " -2.01730708e-10 -1.76417037e-10 -1.70902605e-10 -1.56512439e-10\n",
            " -1.48077539e-10 -1.38869646e-10 -1.19445082e-10 -1.05948808e-10\n",
            " -9.11735111e-11 -7.68250932e-11 -4.99434887e-11 -2.33208064e-11\n",
            "  1.17301840e-12  8.98322914e-12  1.45778566e-11  1.79357480e-11\n",
            "  2.05773313e-11  2.83472760e-11  6.61276254e-11  1.02905791e-10\n",
            "  1.07933527e-10  1.37248301e-10  1.47154263e-10  1.50235595e-10\n",
            "  1.91329168e-10  2.25078341e-10  2.39138661e-10  2.52945440e-10\n",
            "  2.60298563e-10  2.69253428e-10  2.93221147e-10  3.34018263e-10\n",
            "  3.74848304e-10  3.90900848e-10  4.46647264e-10  4.56286654e-10\n",
            "  4.66316438e-10  4.98861197e-10  5.17910756e-10  5.61613402e-10\n",
            "  5.68228704e-10  6.01208053e-10  6.05700178e-10  6.61568349e-10\n",
            "  6.77849396e-10  7.10021616e-10  7.65168035e-10  7.76394660e-10\n",
            "  8.08790898e-10  8.09837184e-10  8.68174581e-10  8.77950339e-10\n",
            "  9.57750703e-10  1.00136493e-09  1.01581349e-09  1.01781165e-09\n",
            "  1.14979337e-09  1.19153004e-09  1.19635617e-09  1.26673590e-09\n",
            "  1.30140230e-09  1.43212625e-09  1.43720073e-09  1.59498582e-09\n",
            "  1.69910665e-09  1.73746943e-09  1.89262905e-09  1.90296137e-09\n",
            "  1.99824901e-09  2.08413188e-09  2.13495002e-09  2.18009110e-09\n",
            "  2.27190931e-09  2.59944712e-09  2.83685589e-09  2.84011309e-09\n",
            "  3.01278178e-09  3.12271348e-09  3.30368788e-09  3.80372557e-09\n",
            "  4.05022479e-09  4.18260702e-09  4.53468971e-09  5.09438665e-09\n",
            "  6.02963870e-09  6.98779974e-09  9.13083480e-09  1.02320175e-08\n",
            "  1.15651105e-08  1.35849878e-08  1.57209102e-08  2.28770267e-08\n",
            "  3.49258392e-08  1.47358714e+00  3.94740676e+00  6.76635454e+00\n",
            "  1.27825659e+01  1.98611790e+01  2.79829387e+01  1.21794126e+02\n",
            "  2.09178961e+02  3.43836011e+02  9.06017549e+02  3.26599028e+03\n",
            "  2.43603495e+05  1.18519582e+08]\n",
            "eigen values of XTX:\n",
            "[1.47358714e+00 3.94740676e+00 6.76635454e+00 1.27825659e+01\n",
            " 1.98611790e+01 2.79829387e+01 1.21794126e+02 2.09178961e+02\n",
            " 3.43836011e+02 9.06017549e+02 3.26599028e+03 2.43603495e+05\n",
            " 1.18519582e+08]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK_x9Soq3NMo"
      },
      "source": [
        "## Important note about the results obtained from $\\texttt{np.linalg.eigh}$## \n",
        "\n",
        "Note that the results from $\\texttt{np.linalg.eigh}$ show some negative eigen values for $XX^\\top$ matrix. \n",
        "\n",
        "However from theory, we know that if $A$ is a $n \\times n$ symmetric and positive semi-definite matrix, then  the eigen values are non-negative. \n",
        "\n",
        "A proof of this result is given below. \n",
        "\n",
        "Hence the results from $\\texttt{np.linalg.eigh}$ should be interpreted carefully. The negative values are again due to numerical errors in algorithms. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teFNSS0mRGj4"
      },
      "source": [
        "$\\mathbf{Result:}$ If $A$ is a $n \\times n$ symmetric and positive semi-definite matrix, then  the eigen values are non-negative. \n",
        "\n",
        "\n",
        "$\\textbf{Recall:}$ Since $A$ is symmetric and positive semi-definite, we know that $x^\\top Ax\\geq 0$ for any $x \\in {\\mathbb{R}}^n$. \n",
        "\n",
        "Now consider $v \\neq \\mathbf{0}$ as an eigen vector of $A$ with eigen value $\\lambda$, we have: $Av = \\lambda v$. \n",
        "\n",
        "Then we have by pre-multiplying by $v^\\top$:\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "v^\\top Av &= v^\\top (\\lambda v) \\nonumber \\\\\n",
        "\\implies \\lambda v^\\top  v &\\geq 0 \\nonumber \n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "Since we know that for a vector $v=\\begin{bmatrix}\n",
        "v_1 \\\\\n",
        "v_2 \\\\\n",
        "\\vdots \\\\\n",
        "v_n\n",
        "\\end{bmatrix} \\in {\\mathbb{R}}^n$, we have $v^\\top v = \\|v\\|_2^2 = \\sum_{i=1}^{n} v_i^2 \\geq 0$ . \n",
        "\n",
        "Since $v \\neq \\mathbf{0}$, we have $\\|v\\|_2^2 > 0$. \n",
        "\n",
        "Thus  from $\\lambda v^\\top  v \\geq 0$ and $v^\\top v > 0$, we have $\\lambda  \\geq 0$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAk-itcEzNOo",
        "outputId": "11a9bda1-ccaf-4dd5-deb0-c3a98ae21251"
      },
      "source": [
        "#checking if XXT and XTX are have same positive eigen values \n",
        "#we will use linalg.eigh in numpy, which can be useful for symmetric matrices \n",
        "\n",
        "print('positive eigen values of XXT:')\n",
        "eig_val_XXT,_ = np.linalg.eigh(XXT)\n",
        "print( eig_val_XXT[np.where(eig_val_XXT > 0)])\n",
        "\n",
        "\n",
        "print('positive eigen values of XXT:')\n",
        "eig_val_XTX,_ = np.linalg.eigh(XTX)\n",
        "print( eig_val_XTX[np.where(eig_val_XTX > 0)])\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive eigen values of XXT:\n",
            "[1.19619165e-11 1.98509559e-11 4.81003319e-11 5.50650362e-11\n",
            " 1.05864068e-10 1.08420716e-10 1.26845060e-10 1.32200620e-10\n",
            " 1.63387440e-10 1.64194831e-10 1.71001422e-10 1.91018311e-10\n",
            " 1.99437077e-10 2.55970367e-10 2.61623591e-10 2.92526690e-10\n",
            " 2.94281569e-10 2.99684548e-10 3.19319082e-10 3.61034601e-10\n",
            " 3.66223500e-10 3.79407573e-10 4.44199084e-10 4.62446296e-10\n",
            " 4.71147017e-10 5.12191237e-10 5.47294991e-10 5.51349781e-10\n",
            " 5.57445546e-10 6.20194840e-10 6.22536313e-10 6.70473051e-10\n",
            " 6.87591180e-10 7.62130803e-10 7.82826751e-10 8.44170375e-10\n",
            " 8.80089159e-10 9.46222583e-10 9.95613391e-10 9.97965138e-10\n",
            " 1.06415963e-09 1.07001197e-09 1.09796732e-09 1.14113850e-09\n",
            " 1.23035395e-09 1.34984892e-09 1.36565621e-09 1.40590431e-09\n",
            " 1.50153880e-09 1.56055664e-09 1.72382377e-09 1.74096149e-09\n",
            " 1.76624627e-09 2.16224095e-09 2.33035521e-09 2.35834990e-09\n",
            " 2.52488531e-09 2.81836724e-09 2.90043644e-09 2.93426979e-09\n",
            " 3.31926660e-09 3.41868192e-09 4.09815682e-09 4.20088012e-09\n",
            " 4.79766955e-09 5.09177043e-09 5.17382388e-09 5.55154572e-09\n",
            " 5.86784807e-09 5.87160981e-09 7.18951456e-09 8.29916904e-09\n",
            " 8.51097376e-09 9.83472930e-09 1.09333592e-08 1.63543461e-08\n",
            " 1.82713289e-08 1.99509807e-08 2.40559233e-08 1.47358714e+00\n",
            " 3.94740676e+00 6.76635455e+00 1.27825659e+01 1.98611790e+01\n",
            " 2.79829387e+01 1.21794126e+02 2.09178961e+02 3.43836011e+02\n",
            " 9.06017549e+02 3.26599028e+03 2.43603495e+05 1.18519582e+08]\n",
            "positive eigen values of XXT:\n",
            "[1.47358714e+00 3.94740676e+00 6.76635454e+00 1.27825659e+01\n",
            " 1.98611790e+01 2.79829387e+01 1.21794126e+02 2.09178961e+02\n",
            " 3.43836011e+02 9.06017549e+02 3.26599028e+03 2.43603495e+05\n",
            " 1.18519582e+08]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hbJAzEBUv5H"
      },
      "source": [
        "##Note about the precision of eigen values:## \n",
        "\n",
        "Please note that there are a few positive eigen values which are close to zero. However in this case, we can guarantee that these values should be zero. \n",
        "\n",
        "These issues highlight some numerical issues when computing eigen values and eigen vectors using $\\texttt{numpy.linalg.eig}$ and $\\texttt{numpy.linalg.eigh}$. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJUKBcl1R1sk",
        "outputId": "0073d1f6-c35d-497d-ebc3-a2e89ad4a949"
      },
      "source": [
        "#check rank of matrices XXT and XTX \n",
        "\n",
        "print('rank(XXT):', np.linalg.matrix_rank(XXT), 'rank(XTX):', np.linalg.matrix_rank(XTX))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rank(XXT): 13 rank(XTX): 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVO0jXmjYHbP"
      },
      "source": [
        "## Rank of matrix $A$ :## \n",
        "\n",
        "Note that for a matrix $A$ of size $m \\times n$, $rank(A)$ is defined as the number of linearly independent rows or columns in $A$. \n",
        "\n",
        "Hence $rank(A) \\leq \\min\\{m,n\\}$. \n",
        "\n",
        "If $rank(A) = \\min\\{m,n\\}$ then the matrix is called full rank. \n",
        "\n",
        "Note that for $\\textit{wine}$ data set, we have $X^\\top X$ to be of size $13 \\times 13$. Also note that $rank(X^\\top X)=13$, hence $X^\\top X$ is full-rank. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMJheGbmz2rZ"
      },
      "source": [
        "## Checking alignment of sample features using dot products ## "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYrwelilW5rZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a8dc81-fe8b-4992-c21c-a918e3e1a58d"
      },
      "source": [
        "#Take some samples of the same class \n",
        "\n",
        "X_class0 = X[np.where(y==0),:].squeeze()\n",
        "print(X_class0.shape)\n",
        "\n",
        "X_class1 = X[np.where(y==1),:].squeeze()\n",
        "print(X_class1.shape)\n",
        "\n",
        "\n",
        "X_class2 = X[np.where(y==2),:].squeeze()\n",
        "print(X_class2.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59, 13)\n",
            "(71, 13)\n",
            "(48, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do4X5gWczOPH",
        "outputId": "4ad394fb-f104-4f21-c7c4-ce9237126c91"
      },
      "source": [
        "#Let us find the dot product between some samples of class 0\n",
        "print(np.dot(X_class0[0]/np.linalg.norm(X_class0[0]),X_class0[1]/np.linalg.norm(X_class0[1])) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9997092287724737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4uUDKAF26bn",
        "outputId": "96c804d2-83da-4a8c-99e8-62e5b8af2a0d"
      },
      "source": [
        "#Let us find the dot product between some samples of class 1\n",
        "print(np.dot(X_class1[30]/np.linalg.norm(X_class1[30]),X_class1[42]/np.linalg.norm(X_class1[42])) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9990245635883316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2o0LY873HWr",
        "outputId": "2c9ab4d8-608f-4623-8284-a9fe09ce3775"
      },
      "source": [
        "#Let us find the dot product between some samples of class 2\n",
        "print(np.dot(X_class2[20]/np.linalg.norm(X_class2[20]),X_class2[32]/np.linalg.norm(X_class2[32])) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9982866107350962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85yHTk43zkn9",
        "outputId": "a4b9d46e-d18d-44c3-9a10-57ec632b6b51"
      },
      "source": [
        "#Let us find the dot product between some samples of class 0 and class 2\n",
        "print(np.dot(X_class0[0]/np.linalg.norm(X_class0[0]),X_class1[10]/np.linalg.norm(X_class1[10])) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9960370718188822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaLMPVFCCYn1"
      },
      "source": [
        "## Exercise ## \n",
        "\n",
        "Try the above code functionalities on $\\textit{iris}$ data set from $\\texttt{scikit-learn}$ package. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDKqPRw13vpR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}