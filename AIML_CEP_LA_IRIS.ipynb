{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIML-CEP-LA.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arvind-maurya/Linear-Algebra/blob/main/AIML_CEP_LA_IRIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MXB7T3QmIYT"
      },
      "source": [
        "#Linear Algebra - Motivation by an application#\n",
        "\n",
        "Let us consider the $\\textit{wine}$ data set from scikit-learn package. Let us load the data set and analyze its structure. \n",
        "\n",
        "We shall check the following:\n",
        "\n",
        "\n",
        "\n",
        "1.   Number of instances (or samples)\n",
        "2.   Number of attributes (or features)\n",
        "3.   Description of attributes \n",
        "4.   Type of class labels (which might not be necessary for today's discussion)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A15Vcn5_mycH"
      },
      "source": [
        "import numpy as np #numpy package will be useful for most of the array operations in the code \n",
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgOvl25BnWyq"
      },
      "source": [
        "#Let us load the wine data and store the result in X_y variable. The idea behind naming of the variable will be illustrated in the next few tabs.\n",
        "X_y = load_iris()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CcM8qwnndnJ",
        "outputId": "c7cae963-1106-443a-bf2d-cdcab6f65410"
      },
      "source": [
        "#Let us print the contents of the X_y variable \n",
        "\n",
        "print(type(X_y))\n",
        "print(X_y)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n",
            "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
            "       [4.9, 3. , 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.3, 0.2],\n",
            "       [4.6, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.6, 1.4, 0.2],\n",
            "       [5.4, 3.9, 1.7, 0.4],\n",
            "       [4.6, 3.4, 1.4, 0.3],\n",
            "       [5. , 3.4, 1.5, 0.2],\n",
            "       [4.4, 2.9, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5.4, 3.7, 1.5, 0.2],\n",
            "       [4.8, 3.4, 1.6, 0.2],\n",
            "       [4.8, 3. , 1.4, 0.1],\n",
            "       [4.3, 3. , 1.1, 0.1],\n",
            "       [5.8, 4. , 1.2, 0.2],\n",
            "       [5.7, 4.4, 1.5, 0.4],\n",
            "       [5.4, 3.9, 1.3, 0.4],\n",
            "       [5.1, 3.5, 1.4, 0.3],\n",
            "       [5.7, 3.8, 1.7, 0.3],\n",
            "       [5.1, 3.8, 1.5, 0.3],\n",
            "       [5.4, 3.4, 1.7, 0.2],\n",
            "       [5.1, 3.7, 1.5, 0.4],\n",
            "       [4.6, 3.6, 1. , 0.2],\n",
            "       [5.1, 3.3, 1.7, 0.5],\n",
            "       [4.8, 3.4, 1.9, 0.2],\n",
            "       [5. , 3. , 1.6, 0.2],\n",
            "       [5. , 3.4, 1.6, 0.4],\n",
            "       [5.2, 3.5, 1.5, 0.2],\n",
            "       [5.2, 3.4, 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.6, 0.2],\n",
            "       [4.8, 3.1, 1.6, 0.2],\n",
            "       [5.4, 3.4, 1.5, 0.4],\n",
            "       [5.2, 4.1, 1.5, 0.1],\n",
            "       [5.5, 4.2, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.2, 1.2, 0.2],\n",
            "       [5.5, 3.5, 1.3, 0.2],\n",
            "       [4.9, 3.6, 1.4, 0.1],\n",
            "       [4.4, 3. , 1.3, 0.2],\n",
            "       [5.1, 3.4, 1.5, 0.2],\n",
            "       [5. , 3.5, 1.3, 0.3],\n",
            "       [4.5, 2.3, 1.3, 0.3],\n",
            "       [4.4, 3.2, 1.3, 0.2],\n",
            "       [5. , 3.5, 1.6, 0.6],\n",
            "       [5.1, 3.8, 1.9, 0.4],\n",
            "       [4.8, 3. , 1.4, 0.3],\n",
            "       [5.1, 3.8, 1.6, 0.2],\n",
            "       [4.6, 3.2, 1.4, 0.2],\n",
            "       [5.3, 3.7, 1.5, 0.2],\n",
            "       [5. , 3.3, 1.4, 0.2],\n",
            "       [7. , 3.2, 4.7, 1.4],\n",
            "       [6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': '/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/iris.csv'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DrlYUrWnxrd",
        "outputId": "ea32ea3e-928f-48c6-b43f-2a9bdbd3cee9"
      },
      "source": [
        "#So we found that the X_y variable is of type sklearn.utils.bunch\n",
        "#further, we see that the X_y variable consists of dictionary-type structures named \"data\",  \"target\" and \"target_names\"\n",
        "\n",
        "# Let us now segregate the data attributes and class labels into separate variables \n",
        "\n",
        "X = X_y.data\n",
        "y = X_y.target\n",
        "\n",
        "print('X shape:', X.shape, 'type(X):', type(X) )\n",
        "print(' y shape:', y.shape, ' type(y):', type(y))\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (150, 4) type(X): <class 'numpy.ndarray'>\n",
            " y shape: (150,)  type(y): <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHQorN2tp-D1",
        "outputId": "34b8024e-04c9-4590-d77b-74328315e3d6"
      },
      "source": [
        "#Thus we see that X and y are numpy ndarrays. \n",
        "#We also see that there are 178 samples (or instances) in the data set and each sample has 13 attributes. \n",
        "#The shape of target variable y indicates that y contains the labels for these 178 samples\n",
        "\n",
        "#We can print the unique labels available in y \n",
        "print(np.unique(y))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyANKhhDpxgb",
        "outputId": "2128aae7-6007-458d-8f0e-155ff12127aa"
      },
      "source": [
        "# Let us also segregate the data set description into a different variable and check the contents\n",
        "X_y_description = X_y.DESCR\n",
        "print('type(X_y_description):', type(X_y_description))\n",
        "print(X_y_description)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(X_y_description): <class 'str'>\n",
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq3Nns2rrTsd",
        "outputId": "2b17691b-8add-4808-a597-54ecb5c60588"
      },
      "source": [
        "#Let us focus our discussion on the feature matrix X and keep aside the label matrix y for the time being.\n",
        "\n",
        "#Let us compute two new matrices from X. \n",
        "\n",
        "XXT = np.matmul(X,np.transpose(X)) #X X^T matrix \n",
        "XTX = np.matmul(X.T,X) #X^T X matrix \n",
        "\n",
        "print('XXT shape:', XXT.shape, 'XTX shape:', XTX.shape)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XXT shape: (150, 150) XTX shape: (4, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J8ka1lTu58y"
      },
      "source": [
        "$XX^\\top$ and $X^\\top X$ are called covariance matrices. \n",
        "\n",
        "In particular, $XX^\\top$ is of shape $\\textit{num samples} \\times \\textit{num samples}$ and captures the correlation (upto scaling) between distinct samples in the data set. Hence we call $XX^\\top$ to be sample covariance matrix. \n",
        "\n",
        "Similarly, $X^\\top X$ is of shape $\\textit{num features} \\times \\textit{num features}$ and captures the correlation (upto scaling) between different attributes in the data set.  Hence we call $X^\\top X$ to be feature covariance matrix. \n",
        "\n",
        "In fact, these covariance matrices satisfy several important properties: \n",
        "\n",
        "\n",
        "\n",
        "1.   $XX^\\top$ and $X^\\top X$ are square and symmetric  \n",
        "2.   $XX^\\top$ and $X^\\top X$ are positive semi-definite (that is, their eigen values are non-negative)\n",
        "3.   $XX^\\top$ and $X^\\top X$ have same positive eigen values.  \n",
        "4.   $XX^\\top$ and $X^\\top X$ have the same rank as $X$ \n",
        "\n",
        "Let us quickly check each of these facts. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5-_UHmht5bd",
        "outputId": "a24d020f-e05a-4d71-e595-b6fb0e2e1f7c"
      },
      "source": [
        "#checking if XXT and XTX are square and symmetric\n",
        "\n",
        "\n",
        "print('XXT matrix:')\n",
        "if XXT.shape[0] == XXT.shape[1]:\n",
        "  print('XXT is square')\n",
        "else:\n",
        "  print('XXT is not square')\n",
        "\n",
        "if np.all(XXT == XXT.T):\n",
        "  print('XXT is symmetric')\n",
        "else:\n",
        "  print('XXT is not symmetric')\n",
        "\n",
        "\n",
        "print('XTX matrix:')\n",
        "if XTX.shape[0] == XTX.shape[1]:\n",
        "  print('XTX is square')\n",
        "else:\n",
        "  print('XTX is not square')\n",
        "\n",
        "if np.all(XTX == XTX.T):\n",
        "  print('XTX is symmetric')\n",
        "else:\n",
        "  print('XTX is not symmetric')\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XXT matrix:\n",
            "XXT is square\n",
            "XXT is symmetric\n",
            "XTX matrix:\n",
            "XTX is square\n",
            "XTX is symmetric\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNLG-KE771-V",
        "outputId": "4ce0fd6a-92f0-4ea8-c429-b770f9396a3b"
      },
      "source": [
        "#checking if XXT and XTX are positive semi-definite\n",
        "#First we will use linalg.eig in numpy, which can be used to find eigen values and eigen vectors for any square matrix\n",
        "\n",
        "print('eigen values of XXT:')\n",
        "eig_val_XXT, eig_vec_XXT = np.linalg.eig(XXT)\n",
        "print(eig_val_XXT)\n",
        "\n",
        "print('eigen values of XTX:')\n",
        "eig_val_XTX, eig_vec_XTX = np.linalg.eig(XTX)\n",
        "print(eig_val_XTX)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eigen values of XXT:\n",
            "[ 9.20830507e+03+0.00000000e+00j  3.15454317e+02+0.00000000e+00j\n",
            "  1.19780429e+01+0.00000000e+00j  3.55257020e+00+0.00000000e+00j\n",
            "  2.06713651e-13+3.58977719e-13j  2.06713651e-13-3.58977719e-13j\n",
            "  3.59549332e-13+0.00000000e+00j -2.79159461e-13+1.24119624e-13j\n",
            " -2.79159461e-13-1.24119624e-13j -3.05793520e-13+2.53582729e-14j\n",
            " -3.05793520e-13-2.53582729e-14j  2.66809575e-13+0.00000000e+00j\n",
            " -2.58688793e-13+1.55670403e-14j -2.58688793e-13-1.55670403e-14j\n",
            " -1.55076916e-13+1.96513575e-13j -1.55076916e-13-1.96513575e-13j\n",
            "  2.29177259e-13+9.80129569e-14j  2.29177259e-13-9.80129569e-14j\n",
            " -7.06028802e-14+2.33137565e-13j -7.06028802e-14-2.33137565e-13j\n",
            "  1.56568083e-14+2.43544381e-13j  1.56568083e-14-2.43544381e-13j\n",
            "  1.16650048e-13+2.10851521e-13j  1.16650048e-13-2.10851521e-13j\n",
            "  6.52440378e-14+2.29364147e-13j  6.52440378e-14-2.29364147e-13j\n",
            "  1.78962085e-13+1.44819273e-13j  1.78962085e-13-1.44819273e-13j\n",
            " -1.95980239e-13+1.29542552e-13j -1.95980239e-13-1.29542552e-13j\n",
            "  2.12306900e-13+6.27047301e-14j  2.12306900e-13-6.27047301e-14j\n",
            "  1.74822220e-13+0.00000000e+00j -1.65154368e-13+0.00000000e+00j\n",
            " -1.35832533e-13+7.27189929e-14j -1.35832533e-13-7.27189929e-14j\n",
            " -1.42420238e-13+4.41592230e-14j -1.42420238e-13-4.41592230e-14j\n",
            " -8.67344941e-14+1.16971312e-13j -8.67344941e-14-1.16971312e-13j\n",
            "  7.25337473e-14+1.16126900e-13j  7.25337473e-14-1.16126900e-13j\n",
            " -3.74459569e-14+1.34716155e-13j -3.74459569e-14-1.34716155e-13j\n",
            "  1.22320572e-13+5.77821874e-14j  1.22320572e-13-5.77821874e-14j\n",
            " -2.29679922e-14+1.32485857e-13j -2.29679922e-14-1.32485857e-13j\n",
            "  1.35203624e-13+2.67996357e-14j  1.35203624e-13-2.67996357e-14j\n",
            "  1.33598518e-13+2.11910896e-14j  1.33598518e-13-2.11910896e-14j\n",
            "  1.35156156e-13+0.00000000e+00j -1.31650538e-13+4.84374293e-15j\n",
            " -1.31650538e-13-4.84374293e-15j -1.13847086e-13+5.60592862e-14j\n",
            " -1.13847086e-13-5.60592862e-14j  1.06861148e-13+6.01171032e-14j\n",
            "  1.06861148e-13-6.01171032e-14j  1.22350688e-13+0.00000000e+00j\n",
            " -6.03192265e-14+1.00038783e-13j -6.03192265e-14-1.00038783e-13j\n",
            " -9.23881250e-14+6.01617980e-14j -9.23881250e-14-6.01617980e-14j\n",
            "  3.62679431e-14+1.07201954e-13j  3.62679431e-14-1.07201954e-13j\n",
            " -2.50835039e-14+1.06633653e-13j -2.50835039e-14-1.06633653e-13j\n",
            "  1.12469097e-13+0.00000000e+00j  8.07234196e-14+6.48425085e-14j\n",
            "  8.07234196e-14-6.48425085e-14j  4.79379334e-14+9.27506683e-14j\n",
            "  4.79379334e-14-9.27506683e-14j  1.03237327e-13+0.00000000e+00j\n",
            " -1.04711147e-13+2.53919337e-14j -1.04711147e-13-2.53919337e-14j\n",
            " -5.06443283e-15+1.04949969e-13j -5.06443283e-15-1.04949969e-13j\n",
            "  8.38419350e-14+5.69695453e-14j  8.38419350e-14-5.69695453e-14j\n",
            "  1.50208545e-14+9.43954040e-14j  1.50208545e-14-9.43954040e-14j\n",
            " -4.95417058e-14+7.98126267e-14j -4.95417058e-14-7.98126267e-14j\n",
            "  9.05508093e-14+2.46029133e-14j  9.05508093e-14-2.46029133e-14j\n",
            " -6.38634786e-14+6.25911864e-14j -6.38634786e-14-6.25911864e-14j\n",
            "  5.43044612e-14+6.97532525e-14j  5.43044612e-14-6.97532525e-14j\n",
            " -2.75540417e-14+8.82241763e-14j -2.75540417e-14-8.82241763e-14j\n",
            " -8.09528851e-14+4.20658431e-14j -8.09528851e-14-4.20658431e-14j\n",
            " -9.95397703e-15+8.83054320e-14j -9.95397703e-15-8.83054320e-14j\n",
            "  8.39403968e-14+0.00000000e+00j  2.49576036e-14+7.85865387e-14j\n",
            "  2.49576036e-14-7.85865387e-14j  5.59268541e-14+4.92662165e-14j\n",
            "  5.59268541e-14-4.92662165e-14j -9.02202121e-14+0.00000000e+00j\n",
            "  7.25199479e-14+2.63234956e-14j  7.25199479e-14-2.63234956e-14j\n",
            " -5.83204523e-14+4.50338776e-14j -5.83204523e-14-4.50338776e-14j\n",
            " -8.27909580e-14+1.34683449e-14j -8.27909580e-14-1.34683449e-14j\n",
            " -1.59674010e-14+7.34216034e-14j -1.59674010e-14-7.34216034e-14j\n",
            "  4.61804091e-14+5.06943114e-14j  4.61804091e-14-5.06943114e-14j\n",
            " -8.22816896e-14+0.00000000e+00j -3.40008504e-14+5.50770535e-14j\n",
            " -3.40008504e-14-5.50770535e-14j  3.30418253e-14+5.07306229e-14j\n",
            "  3.30418253e-14-5.07306229e-14j  6.52728048e-14+0.00000000e+00j\n",
            "  3.56598655e-16+6.08600215e-14j  3.56598655e-16-6.08600215e-14j\n",
            "  5.55186157e-14+0.00000000e+00j -6.43213186e-14+1.86794546e-14j\n",
            " -6.43213186e-14-1.86794546e-14j -4.66451455e-14+3.57583111e-14j\n",
            " -4.66451455e-14-3.57583111e-14j -6.31771077e-14+0.00000000e+00j\n",
            "  1.29443978e-14+4.98460958e-14j  1.29443978e-14-4.98460958e-14j\n",
            " -5.40683010e-14+0.00000000e+00j  3.83284894e-14+1.72384159e-14j\n",
            "  3.83284894e-14-1.72384159e-14j  3.70486228e-14+0.00000000e+00j\n",
            " -2.02224744e-14+2.83735029e-14j -2.02224744e-14-2.83735029e-14j\n",
            "  1.01219534e-14+3.55766784e-14j  1.01219534e-14-3.55766784e-14j\n",
            "  1.86287961e-14+1.70734688e-14j  1.86287961e-14-1.70734688e-14j\n",
            "  4.95123456e-15+2.78692220e-14j  4.95123456e-15-2.78692220e-14j\n",
            "  2.13925759e-14+4.54045090e-15j  2.13925759e-14-4.54045090e-15j\n",
            " -2.12716833e-14+2.22744145e-14j -2.12716833e-14-2.22744145e-14j\n",
            " -3.72745249e-14+0.00000000e+00j -3.15062129e-14+0.00000000e+00j\n",
            " -2.51723783e-14+7.04187868e-15j -2.51723783e-14-7.04187868e-15j\n",
            "  1.47985535e-15+0.00000000e+00j -5.47029059e-30+0.00000000e+00j]\n",
            "eigen values of XTX:\n",
            "[9.20830507e+03 3.15454317e+02 1.19780429e+01 3.55257020e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC5cQ2qS7spe"
      },
      "source": [
        "## Important note about the results obtained from $\\texttt{np.linalg.eig}$## \n",
        "\n",
        "Note that the results from $\\texttt{np.linalg.eig}$ show complex eigen values for $XX^\\top$ matrix. \n",
        "\n",
        "However from theory if $A$ is a real symmetric matrix, then the eigen values need to be real. We present a proof of the result below. \n",
        "\n",
        "So, the results from $\\texttt{np.linalg.eig}$ are due to numerical errors due to floating point approximations and truncations involved in the algorithms used to compute the eigen values and eigen vectors. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0pN9buqQRZw"
      },
      "source": [
        "$\\textbf{Result:}$ If $A$ is a real symmetric matrix, then the eigen values are real. \n",
        "\n",
        "A simple proof is as below: \n",
        "\n",
        "Let $\\lambda$ be a complex number of the form $a+bi$ which is an eigen value for a real symmetric matrix $A$ corresponding to the eigen vector $x\\neq \\mathbf{0}$. Recall that the complex conjugate $\\bar{\\lambda}$ of $\\lambda$ is given by $a-bi$. \n",
        "\n",
        "Then we have:\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "Ax &= \\lambda x \\nonumber \\\\\n",
        "\\text{Taking complex conjugates } & \\text { on both sides, we have} \\nonumber \\\\\n",
        "\\overline{Ax} &= \\overline{\\lambda x} \\nonumber \\\\\n",
        "\\bar{A} \\bar{x} &= \\bar{\\lambda} \\bar{x} \\nonumber \\\\\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "However $\\bar{A} = A$ since $A$ is real. Thus we have $A\\bar{x} = \\bar{\\lambda} \\bar{x}$. Hence $\\bar{x} \\neq \\mathbf{0}$ is an eigen vector of $A$ with a corresponding eigen value $\\bar{\\lambda}$.   \n",
        "\n",
        "Now consider $A \\bar{x} = \\lambda \\bar{x}$. Pre-multiplying by $x^\\top$ we have:\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "x^\\top A \\bar{x} &= \\lambda x^\\top \\bar{x} \\nonumber \\\\\n",
        "(Ax)^\\top \\bar{x} &= \\lambda x^\\top \\bar{x} \\nonumber \\\\\n",
        "\\implies (\\lambda x)^\\top \\bar{x} &= \\lambda x^\\top \\bar{x} \\nonumber \\\\\n",
        "\\lambda x^\\top \\bar{x} &= \\lambda x^\\top \\bar{x} \\nonumber \\\\\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "Since $r=x^\\top \\bar{x} \\neq 0$ is a real quantity $\\textbf{(check this!)}$ we have:   $\\lambda r=\\bar{\\lambda} r \\implies \\lambda =\\bar{\\lambda}$. \n",
        "\n",
        "Now $\\lambda = \\bar{\\lambda} \\implies a+bi = a-bi$ is possible if and only if $b=0$ or $\\lambda$ is a real number. Hence the proof follows. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0zo0Z23ybGu",
        "outputId": "5337978b-48fc-4308-82e4-f654b751bddc"
      },
      "source": [
        "#checking if XXT and XTX are positive semi-definite\n",
        "#we will use linalg.eigh in numpy, which can be useful for symmetric matrices \n",
        "\n",
        "print('eigen values of XXT:')\n",
        "eig_val_XXT, eig_vec_XXT = np.linalg.eigh(XXT)\n",
        "print(eig_val_XXT)\n",
        "\n",
        "print('eigen values of XTX:')\n",
        "eig_val_XTX, eig_vec_XTX = np.linalg.eigh(XTX)\n",
        "print(eig_val_XTX)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eigen values of XXT:\n",
            "[-2.92292744e-12 -2.44525819e-12 -1.97461139e-12 -1.41011744e-12\n",
            " -1.34402091e-12 -1.32965121e-12 -1.13804380e-12 -1.06038913e-12\n",
            " -9.95999691e-13 -8.86376260e-13 -7.28746414e-13 -7.25209156e-13\n",
            " -6.71927383e-13 -5.30233093e-13 -5.09010796e-13 -5.03555718e-13\n",
            " -4.76519706e-13 -4.15023902e-13 -4.13942482e-13 -3.87926173e-13\n",
            " -3.55236239e-13 -3.39333616e-13 -3.28517068e-13 -3.24036492e-13\n",
            " -2.99566157e-13 -2.88725704e-13 -2.81302887e-13 -2.54107852e-13\n",
            " -2.47595233e-13 -2.27253201e-13 -2.17705232e-13 -2.02629641e-13\n",
            " -1.93038188e-13 -1.91208729e-13 -1.89352856e-13 -1.84099599e-13\n",
            " -1.71402416e-13 -1.70751713e-13 -1.61794888e-13 -1.60564337e-13\n",
            " -1.51888093e-13 -1.49597487e-13 -1.39563457e-13 -1.37491763e-13\n",
            " -1.28681780e-13 -1.23852463e-13 -1.19957040e-13 -1.14048333e-13\n",
            " -1.09931182e-13 -1.05338834e-13 -9.77173221e-14 -9.42447642e-14\n",
            " -9.23890410e-14 -8.36051813e-14 -8.23730142e-14 -7.78339975e-14\n",
            " -7.17591605e-14 -7.06411316e-14 -6.99972220e-14 -5.90064125e-14\n",
            " -5.74135222e-14 -4.87504408e-14 -4.41825371e-14 -4.36376941e-14\n",
            " -3.97257134e-14 -3.94182086e-14 -3.43747018e-14 -3.32500435e-14\n",
            " -2.80421662e-14 -2.42455495e-14 -2.20859989e-14 -2.05824648e-14\n",
            " -1.96093354e-14 -1.64630203e-14 -1.00657877e-14 -5.95525230e-15\n",
            "  1.77862335e-15  6.71283462e-15  9.63168067e-15  1.26140720e-14\n",
            "  1.34234014e-14  1.72210709e-14  2.37934738e-14  2.59140554e-14\n",
            "  3.08266568e-14  3.78492664e-14  3.89490751e-14  3.96641925e-14\n",
            "  4.34688340e-14  4.72447552e-14  4.90996625e-14  5.45770122e-14\n",
            "  5.66225562e-14  7.07255412e-14  7.08555942e-14  7.19105463e-14\n",
            "  7.24260443e-14  8.58481441e-14  8.69644393e-14  8.74795996e-14\n",
            "  8.88591118e-14  9.13006705e-14  1.00512965e-13  1.15240657e-13\n",
            "  1.20669925e-13  1.21116851e-13  1.29567582e-13  1.40787321e-13\n",
            "  1.43727538e-13  1.45472345e-13  1.45743872e-13  1.52160031e-13\n",
            "  1.70051674e-13  1.87380859e-13  1.88125705e-13  2.01659771e-13\n",
            "  2.08683265e-13  2.10254485e-13  2.23658767e-13  2.47009374e-13\n",
            "  2.55395404e-13  2.56338789e-13  2.73390006e-13  2.79336888e-13\n",
            "  2.85586979e-13  3.22582390e-13  3.43167805e-13  3.43397503e-13\n",
            "  3.73678190e-13  3.98863546e-13  4.38711916e-13  4.60748583e-13\n",
            "  4.79667560e-13  5.30542622e-13  5.87114509e-13  6.16962966e-13\n",
            "  7.31700391e-13  7.83390608e-13  1.00835397e-12  1.12101906e-12\n",
            "  1.19707076e-12  1.31721082e-12  1.54958460e-12  1.82248600e-12\n",
            "  1.93720267e-12  2.24585452e-12  3.55257020e+00  1.19780429e+01\n",
            "  3.15454317e+02  9.20830507e+03]\n",
            "eigen values of XTX:\n",
            "[3.55257020e+00 1.19780429e+01 3.15454317e+02 9.20830507e+03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK_x9Soq3NMo"
      },
      "source": [
        "## Important note about the results obtained from $\\texttt{np.linalg.eigh}$## \n",
        "\n",
        "Note that the results from $\\texttt{np.linalg.eigh}$ show some negative eigen values for $XX^\\top$ matrix. \n",
        "\n",
        "However from theory, we know that if $A$ is a $n \\times n$ symmetric and positive semi-definite matrix, then  the eigen values are non-negative. \n",
        "\n",
        "A proof of this result is given below. \n",
        "\n",
        "Hence the results from $\\texttt{np.linalg.eigh}$ should be interpreted carefully. The negative values are again due to numerical errors in algorithms. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teFNSS0mRGj4"
      },
      "source": [
        "$\\mathbf{Result:}$ If $A$ is a $n \\times n$ symmetric and positive semi-definite matrix, then  the eigen values are non-negative. \n",
        "\n",
        "\n",
        "$\\textbf{Recall:}$ Since $A$ is symmetric and positive semi-definite, we know that $x^\\top Ax\\geq 0$ for any $x \\in {\\mathbb{R}}^n$. \n",
        "\n",
        "Now consider $v \\neq \\mathbf{0}$ as an eigen vector of $A$ with eigen value $\\lambda$, we have: $Av = \\lambda v$. \n",
        "\n",
        "Then we have by pre-multiplying by $v^\\top$:\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "v^\\top Av &= v^\\top (\\lambda v) \\nonumber \\\\\n",
        "\\implies \\lambda v^\\top  v &\\geq 0 \\nonumber \n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "Since we know that for a vector $v=\\begin{bmatrix}\n",
        "v_1 \\\\\n",
        "v_2 \\\\\n",
        "\\vdots \\\\\n",
        "v_n\n",
        "\\end{bmatrix} \\in {\\mathbb{R}}^n$, we have $v^\\top v = \\|v\\|_2^2 = \\sum_{i=1}^{n} v_i^2 \\geq 0$ . \n",
        "\n",
        "Since $v \\neq \\mathbf{0}$, we have $\\|v\\|_2^2 > 0$. \n",
        "\n",
        "Thus  from $\\lambda v^\\top  v \\geq 0$ and $v^\\top v > 0$, we have $\\lambda  \\geq 0$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAk-itcEzNOo",
        "outputId": "a1cbf504-d9b0-4161-f3ca-6e90eb0ab0eb"
      },
      "source": [
        "#checking if XXT and XTX are have same positive eigen values \n",
        "#we will use linalg.eigh in numpy, which can be useful for symmetric matrices \n",
        "\n",
        "print('positive eigen values of XXT:')\n",
        "eig_val_XXT,_ = np.linalg.eigh(XXT)\n",
        "print( eig_val_XXT[np.where(eig_val_XXT > 0)])\n",
        "\n",
        "\n",
        "print('positive eigen values of XXT:')\n",
        "eig_val_XTX,_ = np.linalg.eigh(XTX)\n",
        "print( eig_val_XTX[np.where(eig_val_XTX > 0)])\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive eigen values of XXT:\n",
            "[1.77862335e-15 6.71283462e-15 9.63168067e-15 1.26140720e-14\n",
            " 1.34234014e-14 1.72210709e-14 2.37934738e-14 2.59140554e-14\n",
            " 3.08266568e-14 3.78492664e-14 3.89490751e-14 3.96641925e-14\n",
            " 4.34688340e-14 4.72447552e-14 4.90996625e-14 5.45770122e-14\n",
            " 5.66225562e-14 7.07255412e-14 7.08555942e-14 7.19105463e-14\n",
            " 7.24260443e-14 8.58481441e-14 8.69644393e-14 8.74795996e-14\n",
            " 8.88591118e-14 9.13006705e-14 1.00512965e-13 1.15240657e-13\n",
            " 1.20669925e-13 1.21116851e-13 1.29567582e-13 1.40787321e-13\n",
            " 1.43727538e-13 1.45472345e-13 1.45743872e-13 1.52160031e-13\n",
            " 1.70051674e-13 1.87380859e-13 1.88125705e-13 2.01659771e-13\n",
            " 2.08683265e-13 2.10254485e-13 2.23658767e-13 2.47009374e-13\n",
            " 2.55395404e-13 2.56338789e-13 2.73390006e-13 2.79336888e-13\n",
            " 2.85586979e-13 3.22582390e-13 3.43167805e-13 3.43397503e-13\n",
            " 3.73678190e-13 3.98863546e-13 4.38711916e-13 4.60748583e-13\n",
            " 4.79667560e-13 5.30542622e-13 5.87114509e-13 6.16962966e-13\n",
            " 7.31700391e-13 7.83390608e-13 1.00835397e-12 1.12101906e-12\n",
            " 1.19707076e-12 1.31721082e-12 1.54958460e-12 1.82248600e-12\n",
            " 1.93720267e-12 2.24585452e-12 3.55257020e+00 1.19780429e+01\n",
            " 3.15454317e+02 9.20830507e+03]\n",
            "positive eigen values of XXT:\n",
            "[3.55257020e+00 1.19780429e+01 3.15454317e+02 9.20830507e+03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hbJAzEBUv5H"
      },
      "source": [
        "##Note about the precision of eigen values:## \n",
        "\n",
        "Please note that there are a few positive eigen values which are close to zero. However in this case, we can guarantee that these values should be zero. \n",
        "\n",
        "These issues highlight some numerical issues when computing eigen values and eigen vectors using $\\texttt{numpy.linalg.eig}$ and $\\texttt{numpy.linalg.eigh}$. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJUKBcl1R1sk",
        "outputId": "0d27a151-4415-4018-b72c-39aa37f2e2c4"
      },
      "source": [
        "#check rank of matrices XXT and XTX \n",
        "\n",
        "print('rank(XXT):', np.linalg.matrix_rank(XXT), 'rank(XTX):', np.linalg.matrix_rank(XTX))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rank(XXT): 4 rank(XTX): 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVO0jXmjYHbP"
      },
      "source": [
        "## Rank of matrix $A$ :## \n",
        "\n",
        "Note that for a matrix $A$ of size $m \\times n$, $rank(A)$ is defined as the number of linearly independent rows or columns in $A$. \n",
        "\n",
        "Hence $rank(A) \\leq \\min\\{m,n\\}$. \n",
        "\n",
        "If $rank(A) = \\min\\{m,n\\}$ then the matrix is called full rank. \n",
        "\n",
        "Note that for $\\textit{wine}$ data set, we have $X^\\top X$ to be of size $13 \\times 13$. Also note that $rank(X^\\top X)=13$, hence $X^\\top X$ is full-rank. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMJheGbmz2rZ"
      },
      "source": [
        "## Checking alignment of sample features using dot products ## "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYrwelilW5rZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afc9f3ff-576c-4447-ec55-4ce94e1b5d0a"
      },
      "source": [
        "#Take some samples of the same class \n",
        "\n",
        "X_class0 = X[np.where(y==0),:].squeeze()\n",
        "print(X_class0.shape)\n",
        "\n",
        "X_class1 = X[np.where(y==1),:].squeeze()\n",
        "print(X_class1.shape)\n",
        "\n",
        "\n",
        "X_class2 = X[np.where(y==2),:].squeeze()\n",
        "print(X_class2.shape)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 4)\n",
            "(50, 4)\n",
            "(50, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do4X5gWczOPH",
        "outputId": "6d1a6301-c8cf-4a56-9e94-bf2741e7e83b"
      },
      "source": [
        "#Let us find the dot product between some samples of class 0\n",
        "print(np.dot(X_class0[0]/np.linalg.norm(X_class0[0]),X_class0[1]/np.linalg.norm(X_class0[1])) )"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9985791635040219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4uUDKAF26bn",
        "outputId": "8012d6b7-8b6e-4926-9ad4-78de9a506d9c"
      },
      "source": [
        "#Let us find the dot product between some samples of class 1\n",
        "print(np.dot(X_class1[30]/np.linalg.norm(X_class1[30]),X_class1[42]/np.linalg.norm(X_class1[42])) )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9999499989909122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2o0LY873HWr",
        "outputId": "47ecbdba-0404-4489-f257-853099061015"
      },
      "source": [
        "#Let us find the dot product between some samples of class 2\n",
        "print(np.dot(X_class2[20]/np.linalg.norm(X_class2[20]),X_class2[32]/np.linalg.norm(X_class2[32])) )"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9993514575830131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85yHTk43zkn9",
        "outputId": "6caed8fc-b83b-44da-acfb-eef9117a1dc5"
      },
      "source": [
        "#Let us find the dot product between some samples of class 0 and class 2\n",
        "print(np.dot(X_class0[0]/np.linalg.norm(X_class0[0]),X_class1[10]/np.linalg.norm(X_class1[10])) )"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9116698722587725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaLMPVFCCYn1"
      },
      "source": [
        "## Exercise ## \n",
        "\n",
        "Try the above code functionalities on $\\textit{iris}$ data set from $\\texttt{scikit-learn}$ package. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDKqPRw13vpR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}